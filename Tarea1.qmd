# Tarea 1

::: {#exr-1}
Ejecute y explica en pocas palabras la salida del código ex_001.py
:::

```{python}
from scipy.stats import multivariate_normal
from mpl_toolkits.mplot3d import axes3d
from scipy.stats import norm
import numpy as np
from scipy.stats import bernoulli
import matplotlib.pyplot as plt
fig_01, ax_01 = plt.subplots(1, 1)
fig_02, ax_02 = plt.subplots(1, 1)
p = 0.3
mean, var, skew, kurt = bernoulli.stats(p, moments='mvsk')
print(mean, var, skew,kurt)

x = np.arange(bernoulli.ppf(0.01, p), bernoulli.ppf(0.99, p))
ax_01.plot(x, bernoulli.pmf(x, p), 'bo', ms=8, label='bernoulli pmf')
ax_01.vlines(x, 0, bernoulli.pmf(x, p), colors='b', lw=5, alpha=0.5)
r = bernoulli.rvs(p, size=1000)
ax_02.hist(r, bins=200)
plt.show()
```

El código posee 3 salidas: 
* Un vector $[0.3, 0.21, 0.87, -1.23]$
* Dos gráficas. 

El vector hace referencia a los momentos de la distribución bernoulli con parámetro $p=0.3$. 
* mean hace referencia a la media. 
* var hace referencia a la varianza.
* skew hace referencia al sesgo. 
* kurt hace referencia a la kurtosis.

Finalmente, las dos gráficas:
* La primera hace referencia a la función de probabilidad. Notemos que $\mathcal{P}[X = 0] = 0.7$, lo que muestra la gráfica. Notemos que la gráfica va de -0.04 a 0.04, por lo tanto no se iba a mostrar el caso $X=1$.  
* La segunda hace referencia a una simulación: Se generaron una muestra de tamaño $N$ variables aleatorias con distribución bernoulli. Como la distribución bernoulli tiene media $Np$, pretende mostrar que en efecto, habrá de forma aproximada $Np$ valores igual a 1 y $N(1-p)$ valores igual a 0. 

::: {#exr-1}
Ejecute y explica en pocas palabras la salida del código ex_002.py
:::


```{python}

fig, ax = plt.subplots(1, 1)
mean, var, skew, kurt = norm.stats(moments='mvsk')

x = np.linspace(norm.ppf(0.01), norm.ppf(0.99), 100)
ax.plot(
    x,
    norm.pdf(x),
    'r-',
    lw=5,
    alpha=0.6,
    label='norm pdf'
)
rv = norm()
ax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')
vals = norm.ppf([0.001, 0.5, 0.999])

np.allclose([0.001, 0.5, 0.999], norm.cdf(vals))

r = norm.rvs(size=50000)

ax.hist(r, density=True, bins='auto', histtype='stepfilled', alpha=0.2)
ax.set_xlim([x[0], x[-1]])
ax.legend(loc='best', frameon=False)
plt.show()


```

El código posee una gráfica. Que hace referencia a una simulación de variables aleatorias normales. Notemos que 
* El elemento en azul, hace referencia a un histograma que refleja las frecuencias de los valores generados.
* Mientras que la linea roja, muestra la función de densidad de una variable aleatoria estándar.

::: {#exr-1}
Ejecute y explica en pocas palabras la salida del código ex_003.py
:::

Para cambiar el vector de medias $\mu$ y la matriz $\Sigma$ hay que prestar atención en la linea donde aparece la función `multivariate_normal()` que de forma simple posee dos parámetros:
* El vector de medias $\mu = [0.5, -0.2]$
* La matriz de covarianza $\Sigma = [[2.0, 0.3], [0.3, 0.5]]$


```{python}

x = np.linspace(0, 5, 100, endpoint=False)
y = multivariate_normal.pdf(x, mean=2.5, cov=0.5)

fig1 = plt.figure()
ax = fig1.add_subplot(111)
ax.plot(x, y)
# plt.show()

x, y = np.mgrid[-5:5:.1, -5:5:.1]
pos = np.dstack((x, y))
rv = multivariate_normal([0.1, 0.5], [[3.0, 0.3], [0.75, 1.5]])
fig2 = plt.figure()
ax2 = fig2.add_subplot(111)
ax2.contourf(x, y, rv.pdf(pos))
# plt.show()

ax = plt.figure().add_subplot(projection='3d')
ax.plot_surface(
    x,
    y,
    rv.pdf(pos),
    edgecolor='royalblue',
    lw=0.5,
    rstride=8,
    cstride=8,
    alpha=0.4
)
ax.contour(x, y, rv.pdf(pos), zdir='z', offset=-.2, cmap='coolwarm')
ax.contour(x, y, rv.pdf(pos), zdir='x', offset=-5, cmap='coolwarm')
ax.contour(x, y, rv.pdf(pos), zdir='y', offset=5, cmap='coolwarm')

ax.set(
    xlim=(-5, 5),
    ylim=(-5, 5),
    zlim=(-0.2, 0.2),
    xlabel='X',
    ylabel='Y',
    zlabel='Z'
)
plt.show()
```





::: {#exr-1}
Generando Normales
:::

```{python}
import numpy as np
from scipy.stats import bernoulli
import matplotlib.pyplot as plt

fig_01, ax_01 = plt.subplots(1, 1)
fig_02, ax_02 = plt.subplots(1, 1)

p = 0.3

x = np.arange(bernoulli.ppf(0.01, p), bernoulli.ppf(0.99, p))
ax_01.plot(x, bernoulli.pmf(x, p), 'bo', ms = 8, label = 'bernoulli pmf')
ax_01.vlines(x, 0, bernoulli.pmf(x, p), colors = 'b', lw = 5, alpha = 0.5)

r = bernoulli.rvs(p, size = 1000)
ax_02.hist(r, bins = 200)

```



```{python}
from scipy.stats import norm

fig, ax = plt.subplots(1,1)

x = np.linspace(norm.ppf(0.01),norm.ppf(0.99), 100)
ax.plot(x, norm.pdf(x),'r-', lw = 5, alpha = 0.6)

r = norm.rvs(size = 1000)

ax.hist(r, density = True, bins = 'auto', histtype = 'stepfilled', alpha = 0.2)
ax.set_xlim(x[0], x[-1])
ax.legend(loc='best', frameon = False)
```



```{python}
from mpl_toolkits.mplot3d import axes3d
from scipy.stats import multivariate_normal

x = np.linspace(0,5,100,endpoint = False)
y = multivariate_normal.pdf(x , mean = 2.5, cov = 0.5)

fig1 = plt.figure()
ax = fig1.add_subplot(111)
ax.plot(x,y)

x, y = np.mgrid[-5:5:.1, -5:5:.1]

pos = np.dstack((x,y))
rv = multivariate_normal([0.5, -0.2], [[2.0,0.3], [0.3,0.5]])
fig2 = plt.figure()
ax2 = fig2.add_subplot(111)
ax2.contourf(x,y, rv.pdf(pos))

ax = plt.figure().add_subplot(projection = '3d')
ax.plot_surface(x,
                y,
                rv.pdf(pos),
                edgecolor = 'royalblue',
                lw = 0.5,
                rstride = 8,
                cstride = 8,
                alpha = 0.5)


```
